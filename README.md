# ImageCaptioningUsingMLTechniques
 
Objective:

The main objective of this project is to generate the captions by just taking the image as an input and producing relative captions.

Introduction:

 
What caption can you give by looking at this picture?
➔	California state university name board 
➔	California state university east bay sign board in the bushes
➔	White letter name board on red and black background.
All of these captions are certainly related to this picture, and some other captions may also exist. But the point we wanted to make is that as human beings, it's too easy for us to just take a look at an image and explain it in a suitable language. 
But can we write a computer program that takes an image as input and produces a relevant caption as output? Yes, it can be done using Deep Learning techniques.

 

How important is this problem in real life scenarios?
Let’s see a few real-world situations where this can be implemented.

1.For Blind People — We can create a product for the blind which will guide them travelling on the roads without the support of anyone else. We can do this by first converting the scene into text and then the text to voice.
2.Image Captioning - It can help, make Google Image Search as good as Google Search, as then every image could be first converted into a caption and then search can be performed based on the caption.
3.Self-driving Car - Automatic driving cars are the best example and if we can properly caption the scene around the car, it can give a boost to the self-driving system.
